# PySpark Sales Data Pipeline

[![Python](https://img.shields.io/badge/python-3.9+-informational.svg)](https://www.python.org)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![documentation style: google](https://img.shields.io/badge/%20style-google-3666d6.svg)](https://google.github.io/styleguide/pyguide.html#s3.8-comments-and-docstrings)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)


## ğŸ“Œ Project Overview
This project processes and analyzes sales transaction data using **PySpark**. It includes:
- **Data Loading**: Reads and normalizes transaction, product, and store data.
- **Data Transformation**: Computes revenue, sales insights, and enriches data.
- **Data Export**: Saves processed data in **Parquet** and **CSV** formats.

---

## ğŸ› ï¸ Setup & Installation
### 1ï¸âƒ£ Prerequisites
Ensure you have the following installed:
- Python 3.9+
- Apache Spark
- Poetry (for dependency management)

### 2ï¸âƒ£ Install Dependencies
Use Poetry to install dependencies:
```bash
poetry shell
poetry lock
poetry install
```
---

## ğŸš€ Running the Project
### 1ï¸âƒ£ Load Data
The `LoadData` class reads sales, products, and store data:
```python
from src.data_processing.load_data import LoadData

loader = LoadData()
loader.load_data()
```

### 2ï¸âƒ£ Transform Data
Use `TransformationData` for sales aggregation and enrichment:
```python
from src.data_processing.transformation_data import TransformationData

transformer = TransformationData(loader.transactions, loader.products, loader.stores)
revenue_df = transformer.calculate_total_revenue()
monthly_sales_df = transformer.calculate_monthly_sales()
enriched_df = transformer.enrich_sales_data()
```

### 3ï¸âƒ£ Export Data
Processed data is saved in Parquet and CSV:
```python
enriched_df.write.parquet("output/enriched_data", partitionBy=["category", "transaction_date"])
revenue_df.write.csv("output/store_revenue.csv", header=True)
```

---

## âœ… Running Tests
This project uses `pytest` and `chispa` for testing. To run tests:
```bash
pytest tests/
```
Tests cover:
- **Date normalization** âœ…
- **Revenue calculations** âœ…
- **Monthly sales aggregation** âœ…
- **Data enrichment** âœ…
- **Price categorization** âœ…

---

## ğŸ“‚ Project Structure
```
ğŸ“ data/
ğŸ“ src/
 â”œâ”€â”€ crosscutting/         # Utility functions & logging
 â”œâ”€â”€ data_models/          # Schema definitions
 â”œâ”€â”€ data_processing/      # Data loading & transformation logic
 â”œâ”€â”€ tests/                # Unit tests
 â”œâ”€â”€ main.py               # Entry point (optional)
ğŸ“ tests/
```

---

## ğŸ“œ License
This project is licensed under the **MIT License**.

---


## ğŸ‘¨â€ğŸ’¼ Authors
Joao Teixeira (joaopteixeira58@gmail.com)

---
